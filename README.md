# Google Gemma Inference
Gemma is a family of 4 new LLM models by Google based on Gemini. It comes in two sizes: 2B and 7B parameters, each with base (pretrained) and instruction-tuned versions. All the variants can be run on various types of consumer hardware, even without quantization, and have a context length of 8K tokens:

Go through follwoing for more
[Gemma: Googleâ€™s new open LLM and Inferencing Gemma](https://medium.com/@iamajithkumar/gemma-googles-new-open-llm-and-inferencing-gemma-2f361d474533)
